vqgan_ckpt: ""
# Have to be derived from VQ-GAN Latent space dimensions
vqgan_ckpt_bp: ""
vqgan_ckpt_bp0: ""
#vqgan_ckpt_bp025: ""
coarse_model: ""
input_img_size: 128
diffusion_img_size: 32
diffusion_depth_size: 32
diffusion_num_channels: 8
dim_mults: [1, 2, 4, 8]
out_dim: 8
results_folder: ./checkpoints/ddpm
results_folder_postfix: ''
load_milestone: ""


batch_size: 2
test_batch_size: 1
num_workers: 4
logger: wandb
objective: pred_x0
save_and_sample_every: 10000
#val_every: 10000
denoising_fn: old_Unet3D
train_lr: 2e-4
timesteps: 100 # number of steps
pose_timesteps: 1
sampling_timesteps: 100 # number of sampling timesteps (using ddim for faster inference [see citation for ddim paper])
loss_type: l2 # L1 or L2
train_num_steps: 500000 # total training steps
gradient_accumulate_every: 1 # gradient accumulation steps
ema_decay: 0.995 # exponential moving average decay
amp: False # turn on mixed precision
num_sample_rows: 1
gpus: 0

